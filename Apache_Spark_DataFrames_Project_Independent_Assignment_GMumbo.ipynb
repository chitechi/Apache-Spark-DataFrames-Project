{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Apache Spark DataFrames Project\n",
        "\n",
        "\n",
        "Project Deliverable\n",
        "\n",
        "You will be required to submit:\n",
        "\n",
        "● A GitHub repository with your project written in Pyspark.\n"
      ],
      "metadata": {
        "id": "SIR1Z3ZdZoy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instructions"
      ],
      "metadata": {
        "id": "XM8ZqCodZrYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a Data professional, you need to perform an analysis by answering questions about some stock market data on Safaricom from the years 2012-2017.\n",
        "You will need to perform the following:\n",
        "\n",
        "\n",
        "**Data Importation and Exploration**\n",
        "\n",
        "● Start a spark session and load the stock file while inferring the data types.\n",
        "\n",
        "● Determine the column names\n",
        "\n",
        "● Make observations about the schema.\n",
        "\n",
        "● Show the first 5 rows\n",
        "\n",
        "● Use the describe method to learn about the data frame\n",
        "\n",
        "**Data Preparation**\n",
        "\n",
        "● Format all the data to 2 decimal places i.e. format_number()\n",
        "\n",
        "● Create a new data frame with a column called HV Ratio that is the ratio of the\n",
        "High Price versus volume of stock traded for a day\n",
        "\n",
        "**Data Analysis**\n",
        "\n",
        "● What day had the Peak High in Price?\n",
        "\n",
        "● What is the mean of the Close column?\n",
        "\n",
        "● What is the max and min of the Volume column?\n",
        "\n",
        "● How many days was the Close lower than 60 dollars?\n",
        "\n",
        "● What percentage of the time was the High greater than 80 dollars?\n",
        "\n",
        "● What is the Pearson correlation between High and Volume?\n",
        "\n",
        "● What is the max High per year?\n",
        "\n",
        "● What is the average Close for each Calendar Month?\n",
        "\n",
        "**Data description**\n",
        "\n",
        "● Dataset URL (CSV File): https://bit.ly/3pmchka\n"
      ],
      "metadata": {
        "id": "sqfgaFKWZ1lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-requisites"
      ],
      "metadata": {
        "id": "Pmtgt-5yatga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing pyspark\n",
        "# ---\n",
        "\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaztvtLXaUbm",
        "outputId": "e010914f-3598-44ec-d2f6-52db6669b501"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=4201b46d1f0cf2adbe6f36beafe2f1b09824d8deb3b9d1e454fc7942fe751b00\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run a local spark session\n",
        "# ---\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "D6j-MuNea-ue"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Importation and Exploration"
      ],
      "metadata": {
        "id": "zqr8KdM_bTQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a spark session and load the stock file while inferring the data types.\n",
        "\n",
        "stock_file_df = spark.read.csv(\"saf_stock.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "Z53x9twHbVgK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the column names\n",
        "print(\"Column Names:\")\n",
        "print(stock_file_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMYKMUyeOLTJ",
        "outputId": "eb698ff1-be58-4bdc-f7d7-f4ecace8c1fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names:\n",
            "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make observations about the schema\n",
        "print(\"Schema:\")\n",
        "stock_file_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWeP9MSAOQdc",
        "outputId": "7d42574d-c8a2-4cd7-c13b-6f0b27026412"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema:\n",
            "root\n",
            " |-- Date: timestamp (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first 5 rows\n",
        "stock_file_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PevMXG4OVq3",
        "outputId": "76d1e784-ffac-43fc-a845-82764407e496"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|               Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03 00:00:00|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04 00:00:00|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05 00:00:00|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06 00:00:00|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09 00:00:00|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the describe method to learn about the data frame\n",
        "\n",
        "stock_file_df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DlIARrNObdR",
        "outputId": "a4f40a20-9cfe-4df6-8bf3-9ae6b2a8cddd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preparation"
      ],
      "metadata": {
        "id": "jw9HFT2TPcrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format all the data to 2 decimal places i.e format_number()\n",
        "\n",
        "from pyspark.sql.functions import format_number\n",
        "numeric_columns = [col[0] for col in stock_file_df.dtypes if col[1] in ['double', 'int']]\n",
        "stock_file_df = stock_file_df.select(stock_file_df[\"Date\"], *(format_number(col, 2).alias(col) for col in numeric_columns))\n",
        "stock_file_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TNNDljNPezD",
        "outputId": "33477ad4-d69f-44bf-d8c4-6226528678dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+-----+-----+-----+-------------+---------+\n",
            "|               Date| Open| High|  Low|Close|       Volume|Adj Close|\n",
            "+-------------------+-----+-----+-----+-----+-------------+---------+\n",
            "|2012-01-03 00:00:00|59.97|61.06|59.87|60.33|12,668,800.00|    52.62|\n",
            "|2012-01-04 00:00:00|60.21|60.35|59.47|59.71| 9,593,300.00|    52.08|\n",
            "|2012-01-05 00:00:00|59.35|59.62|58.37|59.42|12,768,200.00|    51.83|\n",
            "|2012-01-06 00:00:00|59.42|59.45|58.87|59.00| 8,069,400.00|    51.46|\n",
            "|2012-01-09 00:00:00|59.03|59.55|58.92|59.18| 6,679,300.00|    51.62|\n",
            "+-------------------+-----+-----+-----+-----+-------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column \"HV Ratio\" that is the ratio of the High Price versus volume of stock traded for a day\n",
        "\n",
        "from pyspark.sql.functions import regexp_replace, col\n",
        "stock_file_df = stock_file_df.withColumn(\"Volume\", regexp_replace(col(\"Volume\"), \",\", \"\"))\n",
        "stock_file_df = stock_file_df.withColumn(\"HV Ratio\", stock_file_df.High/ stock_file_df.Volume)\n",
        "stock_file_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejq_4WhIRAI0",
        "outputId": "96c8c67a-cac4-474a-d654-037bda1981b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
            "|               Date| Open| High|  Low|Close|     Volume|Adj Close|            HV Ratio|\n",
            "+-------------------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
            "|2012-01-03 00:00:00|59.97|61.06|59.87|60.33|12668800.00|    52.62|4.819714574387472E-6|\n",
            "|2012-01-04 00:00:00|60.21|60.35|59.47|59.71| 9593300.00|    52.08|6.290848821573389...|\n",
            "|2012-01-05 00:00:00|59.35|59.62|58.37|59.42|12768200.00|    51.83|4.669413073103491E-6|\n",
            "|2012-01-06 00:00:00|59.42|59.45|58.87|59.00| 8069400.00|    51.46|7.367338339901356E-6|\n",
            "|2012-01-09 00:00:00|59.03|59.55|58.92|59.18| 6679300.00|    51.62|8.915604928660188E-6|\n",
            "+-------------------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Analysis"
      ],
      "metadata": {
        "id": "lJMGHPZeVjvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SQLContext\n",
        "\n",
        "sqlCtx = SQLContext(spark)\n",
        "stock_file_df.createOrReplaceTempView(\"stock_data\")\n",
        "\n",
        "print(\"Tables in SQLContext:\", sqlCtx.tableNames())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkzTSKF2XIkv",
        "outputId": "7dbd58fb-dba5-46eb-ce62-a827f539f003"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables in SQLContext: ['stock_data']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What day had the Peak High in Price?\n",
        "day_peak_high_price = sqlCtx.sql(\"SELECT Date, High FROM stock_data ORDER BY High DESC LIMIT 1\")\n",
        "day_peak_high_price.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sxqBESjXKaK",
        "outputId": "f249cd58-d44b-48c2-ed9d-441f4c222171"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+\n",
            "|               Date| High|\n",
            "+-------------------+-----+\n",
            "|2015-01-13 00:00:00|90.97|\n",
            "+-------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the mean of the Close column?\n",
        "mean_query = \"\"\"\n",
        "select mean(Close)\n",
        "from stock_data\n",
        "\"\"\"\n",
        "sqlCtx.sql(mean_query).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDBzdV6EXf8b",
        "outputId": "0275d6c8-ebd5-4e2a-9f99-cc03f5b04e7a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|      mean(Close)|\n",
            "+-----------------+\n",
            "|72.38844992050863|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What is the max and min of the Volume column?\n",
        "max_min_query = \"\"\"\n",
        "select min(Volume) as min_Volume, max(Volume) as max_Volume\n",
        "from stock_data\n",
        "\"\"\"\n",
        "sqlCtx.sql(max_min_query).show()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT_kRvetYotm",
        "outputId": "e7246f48-3356-48ac-907b-a1141453c095"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+\n",
            "| min_Volume|max_Volume|\n",
            "+-----------+----------+\n",
            "|10010500.00|9994400.00|\n",
            "+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many days was the Close lower than 60 dollars?\n",
        "days_result = sqlCtx.sql(\"SELECT COUNT(Date) FROM stock_data WHERE Close < 60\")\n",
        "\n",
        "days_result.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8AbMeMUZKfH",
        "outputId": "f79c9e9c-cd80-4aa3-e1eb-076b6842e400"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|count(Date)|\n",
            "+-----------+\n",
            "|         81|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What percentage of the time was the High greater than 80 dollars?\n",
        "\n",
        "percent_result = sqlCtx.sql(\"SELECT COUNT(*) FROM stock_data WHERE High > 80\")\n",
        "high_count = percent_result.collect()[0][0]\n",
        "\n",
        "percent_result = sqlCtx.sql(\"SELECT COUNT(*) FROM stock_data\")\n",
        "total_count = percent_result.collect()[0][0]\n",
        "\n",
        "percentage = (high_count / total_count) * 100\n",
        "\n",
        "print(\"Percentage of days with High price > 80: {:.2f}%\".format(percentage))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkkEoXEHZ1Te",
        "outputId": "66e37ee7-ff29-493e-be7a-baad76919085"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of days with High price > 80: 8.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the Pearson correlation between High and Volume?\n",
        "\n",
        "from pyspark.sql.functions import corr\n",
        "pearson_result = stock_file_df.select(corr(\"High\", \"Volume\").alias(\"correlation\")).collect()[0][0]\n",
        "print(\"Pearson correlation between High and Volume:\", pearson_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_umP97eAauQG",
        "outputId": "875fd301-552c-4cdc-e2e5-f42cb533e1e0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson correlation between High and Volume: -0.33843260582148915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the max High per year?\n",
        "max_result = sqlCtx.sql(\"SELECT year(Date) as year, max(High) as max_high FROM stock_data GROUP BY year(Date) ORDER BY max_high DESC\")\n",
        "\n",
        "# Show the result\n",
        "max_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4wyvYaEbETR",
        "outputId": "72bfd36c-78d0-4d49-deb2-0cc6649f1dba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+\n",
            "|year|max_high|\n",
            "+----+--------+\n",
            "|2015|   90.97|\n",
            "|2014|   88.09|\n",
            "|2013|   81.37|\n",
            "|2012|   77.60|\n",
            "|2016|   75.19|\n",
            "+----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the average Close for each Calendar Month?\n",
        "avg_query = \"\"\"\n",
        "select mean(Close) as mean_per_month, MONTH(Date) as month_no\n",
        "from stock_data\n",
        "group by month_no\n",
        "order by month_no\n",
        "\"\"\"\n",
        "sqlCtx.sql(avg_query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_qv5BO0fc3N",
        "outputId": "2c5b825a-8354-4c19-d090-1abb48a1ddb9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------+\n",
            "|   mean_per_month|month_no|\n",
            "+-----------------+--------+\n",
            "|71.44801980198022|       1|\n",
            "|71.30680412371134|       2|\n",
            "|71.77794392523363|       3|\n",
            "|72.97361904761907|       4|\n",
            "|72.30971698113206|       5|\n",
            "|72.49537735849057|       6|\n",
            "|74.43971962616824|       7|\n",
            "|73.02981818181819|       8|\n",
            "|72.18411764705883|       9|\n",
            "|71.57854545454546|      10|\n",
            "|72.11108910891085|      11|\n",
            "|72.84792452830189|      12|\n",
            "+-----------------+--------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}